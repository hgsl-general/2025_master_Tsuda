{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03494fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        race_id  着 順  枠 番  馬 番         馬名  性齢  斤量    騎手     タイム     着差    単勝  \\\n",
      "0  202401010101    1    5    5    ポッドベイダー  牡2  55  佐々木大  1:08.8    NaN   1.2   \n",
      "1  202401010101    2    2    2  ニシノクードクール  牝2  55   武藤雅  1:09.1  1.3/4  10.2   \n",
      "2  202401010101    3    3    3    ロードヴェルト  牡2  55  横山武史  1:09.4  1.3/4   7.9   \n",
      "3  202401010101    4    1    1   ルージュアマリア  牝2  55  永野猛蔵  1:10.0  3.1/2   5.9   \n",
      "4  202401010101    5    4    4   ロードヴァルカン  牡2  54  角田大河  1:10.1     クビ  21.3   \n",
      "\n",
      "   人 気      馬体重       調教師    horse_id  jockey_id  \n",
      "0    1  462(-2)  [東] 上原佑紀  2022105244        NaN  \n",
      "1    4  452(-2)  [東] 武藤善則  2022106999        NaN  \n",
      "2    3  416(+6)  [西] 牧浦充徳  2022100639        NaN  \n",
      "3    2  410(+6)  [東] 黒岩陽一  2022105762        NaN  \n",
      "4    5  438(-2)  [西] 中村直也  2022100660        NaN  \n"
     ]
    }
   ],
   "source": [
    "# netkeiba_race_scrape_and_parse.py\n",
    "# 目的:\n",
    "#  1) db.netkeiba.com/race/<race_id>/ を取得してHTML保存（キャッシュ）\n",
    "#  2) EUC-JP でデコードして文字化け回避\n",
    "#  3) BeautifulSoupで正規化して pd.read_html でテーブル抽出\n",
    "#  4) レース結果テーブルを自動特定\n",
    "#  5) horse_id / jockey_id を href から抽出して DataFrame に付与\n",
    "\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "BASE = \"https://db.netkeiba.com\"\n",
    "\n",
    "# 保存先（好きに変えてOK）\n",
    "DATA_DIR = Path(\"data_netkeiba\")\n",
    "HTML_DIR = DATA_DIR / \"html\"\n",
    "HTML_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# polite settings（最初は遅く）\n",
    "SLEEP_MIN = 2.5\n",
    "SLEEP_MAX = 6.0\n",
    "\n",
    "\n",
    "def fetch_html(url: str, save_path: Path, session: requests.Session) -> bytes:\n",
    "    \"\"\"\n",
    "    url からHTMLを取得して save_path に保存（存在すれば再取得しない）\n",
    "    戻り値: HTML bytes\n",
    "    \"\"\"\n",
    "    if save_path.exists():\n",
    "        return save_path.read_bytes()\n",
    "\n",
    "    r = session.get(url, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(f\"HTTP {r.status_code}: {url}\")\n",
    "\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    save_path.write_bytes(r.content)\n",
    "\n",
    "    time.sleep(random.uniform(SLEEP_MIN, SLEEP_MAX))\n",
    "    return r.content\n",
    "\n",
    "\n",
    "def decode_netkeiba(html_bytes: bytes) -> str:\n",
    "    \"\"\"\n",
    "    netkeiba系は EUC-JP のことが多いのでまずEUC-JPで読む。\n",
    "    ダメなら UTF-8 / CP932 も試す。\n",
    "    \"\"\"\n",
    "    for enc in [\"euc-jp\", \"cp932\", \"utf-8\"]:\n",
    "        try:\n",
    "            return html_bytes.decode(enc, errors=\"strict\")\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    # 最後の保険（多少欠けてもいいから進める）\n",
    "    return html_bytes.decode(\"euc-jp\", errors=\"ignore\")\n",
    "\n",
    "\n",
    "def make_soup(html: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    BeautifulSoup を作る。lxml が使えなければ html.parser にフォールバック。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return BeautifulSoup(html, \"lxml\")  # ← ここは \"lxml\"（lmxlじゃない）\n",
    "    except Exception:\n",
    "        return BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "def read_all_tables(soup: BeautifulSoup) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    soup から pandas の read_html で全テーブルを抜く。\n",
    "    FutureWarning回避のため StringIO を使う。\n",
    "    \"\"\"\n",
    "    return pd.read_html(StringIO(str(soup)))\n",
    "\n",
    "\n",
    "def is_race_result_table(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    レース結果っぽいテーブルかどうか判定。\n",
    "    netkeibaは列名が崩れることもあるので、複数条件でゆるく判定する。\n",
    "    \"\"\"\n",
    "    cols = [str(c).strip() for c in df.columns]\n",
    "    colset = set(cols)\n",
    "\n",
    "    # よくある列名\n",
    "    must_have_any = [{\"着順\", \"順位\"}, {\"馬名\"}, {\"騎手\"}]\n",
    "    hits = 0\n",
    "    for s in must_have_any:\n",
    "        if len(colset.intersection(s)) > 0:\n",
    "            hits += 1\n",
    "\n",
    "    # 行数がそこそこある & 主要列がそこそこ揃ってる\n",
    "    return (df.shape[0] >= 5) and (hits >= 2)\n",
    "\n",
    "\n",
    "def normalize_header(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Unnamed地獄対策：\n",
    "    もし列名に「着順」「馬名」などが入っていなければ\n",
    "    先頭行がヘッダの可能性があるので繰り上げる。\n",
    "    \"\"\"\n",
    "    cols = set(map(str, df.columns))\n",
    "    if (\"馬名\" in cols) or (\"着順\" in cols) or (\"順位\" in cols):\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    # 先頭行をヘッダにしてみる\n",
    "    df2 = df.copy()\n",
    "    df2.columns = df2.iloc[0]\n",
    "    df2 = df2.iloc[1:].reset_index(drop=True)\n",
    "    return df2\n",
    "\n",
    "\n",
    "def extract_ids(soup: BeautifulSoup) -> tuple[dict[str, str], dict[str, str]]:\n",
    "    \"\"\"\n",
    "    aタグの href から horse_id / jockey_id を抽出して\n",
    "    表示テキスト（馬名/騎手名）→ID の辞書を返す。\n",
    "    \"\"\"\n",
    "    horse_map: dict[str, str] = {}\n",
    "    jockey_map: dict[str, str] = {}\n",
    "\n",
    "    for a in soup.select(\"a[href]\"):\n",
    "        text = a.get_text(strip=True)\n",
    "        href = a.get(\"href\", \"\")\n",
    "\n",
    "        # horse\n",
    "        if \"/horse/\" in href:\n",
    "            m = re.search(r\"/horse/(\\d+)/\", href)\n",
    "            if m and text:\n",
    "                # 同名が出る場合があるので「最初に見つかったもの」を優先\n",
    "                horse_map.setdefault(text, m.group(1))\n",
    "\n",
    "        # jockey\n",
    "        if \"/jockey/\" in href:\n",
    "            m = re.search(r\"/jockey/(\\d+)/\", href)\n",
    "            if m and text:\n",
    "                jockey_map.setdefault(text, m.group(1))\n",
    "\n",
    "    return horse_map, jockey_map\n",
    "\n",
    "\n",
    "def parse_race_page(html_bytes: bytes) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    レースページHTML(bytes) → 結果テーブル(DataFrame) を返す\n",
    "    horse_id/jockey_id も付与。\n",
    "    \"\"\"\n",
    "    html = decode_netkeiba(html_bytes)\n",
    "    soup = make_soup(html)\n",
    "\n",
    "    tables = read_all_tables(soup)\n",
    "    if not tables:\n",
    "        raise RuntimeError(\"No tables found. The page structure might have changed.\")\n",
    "\n",
    "    # 結果っぽいテーブルを探す\n",
    "    cand = [t for t in tables if is_race_result_table(t)]\n",
    "    if not cand:\n",
    "        # だめなら「一番行数が多いテーブル」を候補にする\n",
    "        df = max(tables, key=lambda x: x.shape[0])\n",
    "    else:\n",
    "        # 候補の中で最も行数が多いものを採用\n",
    "        df = max(cand, key=lambda x: x.shape[0])\n",
    "\n",
    "    df = normalize_header(df)\n",
    "\n",
    "    # ID抽出\n",
    "    horse_map, jockey_map = extract_ids(soup)\n",
    "\n",
    "    # 列名ゆらぎ対策\n",
    "    if \"馬名\" in df.columns:\n",
    "        df[\"horse_id\"] = df[\"馬名\"].astype(str).map(horse_map)\n",
    "    else:\n",
    "        df[\"horse_id\"] = None\n",
    "\n",
    "    if \"騎手\" in df.columns:\n",
    "        df[\"jockey_id\"] = df[\"騎手\"].astype(str).map(jockey_map)\n",
    "    else:\n",
    "        df[\"jockey_id\"] = None\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_race_df(race_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    race_id を指定して、HTML取得→パース→DataFrame を返す。\n",
    "    \"\"\"\n",
    "    url = f\"{BASE}/race/{race_id}/\"\n",
    "    save_path = HTML_DIR / \"race\" / f\"{race_id}.html\"\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; research-bot/0.1; +local)\",\n",
    "        \"Accept-Language\": \"ja,en;q=0.8\",\n",
    "    })\n",
    "\n",
    "    html_bytes = fetch_html(url, save_path, session)\n",
    "    df = parse_race_page(html_bytes)\n",
    "    df.insert(0, \"race_id\", race_id)\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 例：任意の race_id を入れて動作確認\n",
    "    # race_id はあなたが取得したいレースのIDに置き換えてください\n",
    "    race_id = \"202401010101\"  # ダミー（ここを実在IDに）\n",
    "    df = get_race_df(race_id)\n",
    "\n",
    "    # 表示\n",
    "    print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8b166",
   "metadata": {},
   "source": [
    "# セル1：開催日（YYYYMMDD）→その日の race_id を全部集める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b36c017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- セル1（最終版）: スマホ版レース一覧から race_id を確実に抜く ---\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from datetime import date, timedelta\n",
    "from typing import List, Set\n",
    "\n",
    "import requests\n",
    "\n",
    "# スマホ版（HTMLに情報が残りやすい）\n",
    "RACE_LIST_URL = \"https://race.sp.netkeiba.com/?pid=race_list&kaisai_date={yyyymmdd}\"\n",
    "\n",
    "SLEEP_MIN = 0.8\n",
    "SLEEP_MAX = 2.0\n",
    "\n",
    "sess = requests.Session()\n",
    "sess.headers.update({\n",
    "    # スマホっぽいUAにして「ブラウザで見えてるHTML」に寄せる\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) \"\n",
    "        \"AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"ja,en;q=0.8\",\n",
    "})\n",
    "\n",
    "def yyyymmdd(d: date) -> str:\n",
    "    return d.strftime(\"%Y%m%d\")\n",
    "\n",
    "def get_race_ids_for_date(d: date, debug: bool = False) -> List[str]:\n",
    "    \"\"\"\n",
    "    【何をしている？】\n",
    "    - スマホ版のレース一覧ページを取得\n",
    "    - HTML “全文” から race_id=12桁 を全部抜く（hrefに依存しない）\n",
    "    - 重複を除いて race_id リストを返す\n",
    "    \"\"\"\n",
    "    url = RACE_LIST_URL.format(yyyymmdd=yyyymmdd(d))\n",
    "    r = sess.get(url, timeout=30)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        if debug:\n",
    "            print(\"[skip]\", d, \"status\", r.status_code, \"url\", url)\n",
    "        return []\n",
    "\n",
    "    # 文字化け回避（netkeibaはEUC-JP系が混ざることがある）\n",
    "    r.encoding = r.apparent_encoding\n",
    "    html = r.text\n",
    "\n",
    "    # hrefだけを見ると取り逃がすことがあるので、HTML全体から抜く\n",
    "    ids = sorted(set(re.findall(r\"race_id=(\\d{12})\", html)))\n",
    "\n",
    "    if debug:\n",
    "        print(\"[date]\", d, \"url\", url, \"status\", r.status_code, \"ids\", len(ids))\n",
    "        print(\"  sample ids:\", ids[:5])\n",
    "        # 0件の時は「本当にrace_idが無いHTML」か確認\n",
    "        if len(ids) == 0:\n",
    "            print(\"  debug: 'race_id=' count =\", html.count(\"race_id=\"))\n",
    "            print(\"  head:\", html[:500])\n",
    "\n",
    "    time.sleep(random.uniform(SLEEP_MIN, SLEEP_MAX))\n",
    "    return ids\n",
    "\n",
    "def get_race_ids_in_range(start: date, end: date, debug: bool = False) -> List[str]:\n",
    "    \"\"\"\n",
    "    【何をしている？】\n",
    "    - start〜end（両端含む）を日ごとに回して race_id を集約\n",
    "    \"\"\"\n",
    "    all_ids: Set[str] = set()\n",
    "    d = start\n",
    "    while d <= end:\n",
    "        ids = get_race_ids_for_date(d, debug=debug)\n",
    "        all_ids.update(ids)\n",
    "        d += timedelta(days=1)\n",
    "    return sorted(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f8e1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: 200\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"EUC-JP\">\n",
      "\n",
      "<!-- block=meta_tag_common_race (d) -->\n",
      "<meta http-equiv=\"content-language\" content=\"ja\">\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=0.5, user-scalable=yes\">\n",
      "\n",
      "<meta name=\"format-detection\" content=\"telephone=no\" />\n",
      "<meta name=\"description\" content=\"JRA開催レースのレース一覧です。JRA開催レースの出馬表や最新オッズ、レース結果速報、払戻情報をはじめ、競馬予想やデータ分析など予想に役立つ情報も満載です。\" />\n",
      "<meta name=\"keywords\" content=\"競馬,keiba,出馬表,オッズ,予想,レース結果,払戻し,結果速報,競馬予想,ネット競馬,netkeiba\" />\n",
      "<meta name=\"thumbnail\" content=\"https://www.netkeiba.com/style/netkeiba.ja/image/netkeiba.png\" />\n",
      "<!-- ogp用 -->\n",
      "<meta property=\"og:site_name\" content=\"netkeiba\" />\n",
      "<meta property=\"og:type\" content=\"article\" />\n",
      "<meta property=\"og:title\" content=\"レース一覧 | レース情報(JRA) - netkeiba\" />\n",
      "<meta property=\"og:url\" content=\"https://race.netkeiba.com/top/race_list.html\" />\n",
      "<meta property=\"og:description\" content=\"JRA開催レースのレース一覧です。JRA開催レースの出馬表や最新オッズ、レース結果速報、払戻情報をはじめ、競馬予想やデータ分析など予想に役立つ情報も満載です。\" />\n",
      "<meta property=\"og:image\" content=\"https://www.netkeiba.com/style/netkeiba.ja/image/netkeiba.png\" />\n",
      "<!-- Twitter用 -->\n",
      "<meta property=\"twitter:card\" content=\"summary\">\n",
      "<meta property=\"twitter:site\" content=\"@netkeiba\">\n",
      "<!-- Facebook用 -->\n",
      "<meta property=\"fb:admins\" content=\"30367\" />\n",
      "<!-- アノテーション -->\n",
      "<link rel=\"canonical\" href=\"https://race.netkeiba.com/top/race_list.html\" />\n",
      "<link rel=\"alternate\" media=\"only screen and (max-width: 640px)\" href=\"https://race.sp.netkeiba.com/?pid=race_list\" />\n",
      "<link rel=\"alternate\" type=\"application/rss+xml\" href=\"https://rss.netkeiba.com/?pid=rss_netkeiba&site=netkeiba\" />\n",
      "<link rel=\"apple-touch-icon\" href=\"https://rcdn.netkeiba.com/img.sp/common/img/common/icon_home.png\" />\n",
      "<title>レース一覧 | レース情報(JRA) - netkeiba</title>\n",
      "<!-- 共通css include -->\n",
      "<!-- block=race_common_css02 (d) -->\n",
      "<link rel=\"apple-touch-icon\" href=\"https://rcdn.netkeiba.com/img.sp/common/img/common/icon_home.png\"/>\n",
      "<link rel=\"shortcut icon\" href=\"https://cdn.netke\n"
     ]
    }
   ],
   "source": [
    "# デバッグ用：1日だけHTMLを確認\n",
    "d = end - timedelta(days=7)\n",
    "url = RACE_LIST_URL.format(yyyymmdd=d.strftime(\"%Y%m%d\"))\n",
    "r = sess.get(url, timeout=30)\n",
    "r.encoding = r.apparent_encoding\n",
    "\n",
    "print(\"status:\", r.status_code)\n",
    "print(r.text[:2000])  # 先頭だけ表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0c1a765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 ['202506050701', '202506050702', '202506050703', '202506050704', '202506050705']\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "test_day = date(2025, 12, 28)\n",
    "ids = get_race_ids_for_date(test_day)\n",
    "print(len(ids), ids[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7043eaa",
   "metadata": {},
   "source": [
    "# セル2：過去N年分の race_id を集める（まずは1〜2年で試す）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3037e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num race_ids: 3455\n",
      "sample: ['202501010101', '202501010102', '202501010103', '202501010104', '202501010105', '202501010106', '202501010107', '202501010108', '202501010109', '202501010110']\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "# 例：まずは過去365日（1年）で試す → 動いたら 2年(730日)、3年…と増やす\n",
    "end = date.today()\n",
    "start = end - timedelta(days=365)\n",
    "\n",
    "race_ids = get_race_ids_in_range(start, end)\n",
    "print(\"num race_ids:\", len(race_ids))\n",
    "print(\"sample:\", race_ids[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae140d",
   "metadata": {},
   "source": [
    "# セル3：race_id を回して “学習用の生データ(train_raw.csv)” を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a895f5d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[saved]\u001b[39m\u001b[33m\"\u001b[39m, out_csv, \u001b[33m\"\u001b[39m\u001b[33mshape:\u001b[39m\u001b[33m\"\u001b[39m, df_all.shape)\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_all\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m df_all = \u001b[43mbuild_train_raw_from_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrace_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_raw.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m df_all.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mbuild_train_raw_from_ids\u001b[39m\u001b[34m(race_ids, out_csv)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, rid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(race_ids, \u001b[32m1\u001b[39m):\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         d = \u001b[43mget_race_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrid\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ← ここはあなたの既存関数\u001b[39;00m\n\u001b[32m     14\u001b[39m         dfs.append(d)\n\u001b[32m     15\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m50\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 200\u001b[39m, in \u001b[36mget_race_df\u001b[39m\u001b[34m(race_id)\u001b[39m\n\u001b[32m    194\u001b[39m session = requests.Session()\n\u001b[32m    195\u001b[39m session.headers.update({\n\u001b[32m    196\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMozilla/5.0 (compatible; research-bot/0.1; +local)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    197\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAccept-Language\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mja,en;q=0.8\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    198\u001b[39m })\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m html_bytes = \u001b[43mfetch_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m df = parse_race_page(html_bytes)\n\u001b[32m    202\u001b[39m df.insert(\u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrace_id\u001b[39m\u001b[33m\"\u001b[39m, race_id)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mfetch_html\u001b[39m\u001b[34m(url, save_path, session)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_path.exists():\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m save_path.read_bytes()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m r = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHTTP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/site-packages/urllib3/connectionpool.py:793\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    790\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    792\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    809\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/site-packages/urllib3/connectionpool.py:537\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/site-packages/urllib3/connection.py:466\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    469\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nb312/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_train_raw_from_ids(race_ids, out_csv=\"train_raw.csv\"):\n",
    "    \"\"\"\n",
    "    【何をしている？】\n",
    "    - 入力: race_idリスト\n",
    "    - 1つずつ get_race_df(race_id) を実行して結果表を取得\n",
    "    - 全部結合して out_csv に保存\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for i, rid in enumerate(race_ids, 1):\n",
    "        try:\n",
    "            d = get_race_df(rid)  # ← ここはあなたの既存関数\n",
    "            dfs.append(d)\n",
    "            if i % 50 == 0:\n",
    "                print(f\"[progress] {i}/{len(race_ids)} races\")\n",
    "        except Exception as e:\n",
    "            print(\"[skip]\", rid, e)\n",
    "\n",
    "    if not dfs:\n",
    "        raise RuntimeError(\"No races collected. race_ids might be empty or blocked.\")\n",
    "\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    df_all.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"[saved]\", out_csv, \"shape:\", df_all.shape)\n",
    "    return df_all\n",
    "\n",
    "df_all = build_train_raw_from_ids(race_ids, out_csv=\"train_raw.csv\")\n",
    "df_all.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nb312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
